{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Hospital Stay Duration Prediction Model**\n",
        "\n",
        "This module implements a machine learning approach to predict hospital length of stay\n",
        "using baseline patient characteristics, vital sign statistics, and diagnosis information.\n",
        "The model avoids complex time-series analysis by using statistical summaries and measurement\n",
        "patterns to represent patient status.\n",
        "\n",
        "Features used in the prediction:\n",
        "\n",
        "Dataset Tables:\n",
        "\n",
        "1. Vital Signs Dataset (over_20_records.csv):\n",
        "   - Contains patient measurements during hospitalization\n",
        "   - Key columns: PatientNum, PatientAgeAtAdmission, TotalHospitalDays, Execution_Date,\n",
        "     HoursFromAdmission, Parameter_Name, ResultValue, NumericResult, ReadingSequence\n",
        "   - Each row represents a single measurement for a specific patient and parameter\n",
        "\n",
        "2. Diagnoses Dataset (patients_diagnoses.csv):\n",
        "   - Contains patients' diagnostic information using ICD-9/ICD-10 codes\n",
        "   - Key columns: PatientNum, ICD9\n",
        "   - Each row represents a single diagnosis for a specific patient\n",
        "\n",
        "\n",
        "1. Baseline Patient Features:\n",
        "   - Age at admission\n",
        "   - BMI (body mass index)\n",
        "   - Weight\n",
        "\n",
        "2. Vital Sign Statistical Features:\n",
        "   For each vital sign (heart rate, blood pressure, temperature, etc.):\n",
        "   - Measurement frequency (count)\n",
        "   - Statistical summaries (mean, median, std, min, max, range, trend)\n",
        "\n",
        "3. Diagnosis-Based Features:\n",
        "   - Total diagnosis count\n",
        "   - Binary indicators for major disease categories\n",
        "   - Binary indicators for common specific diagnosis codes\n",
        "\n",
        "The implementation follows these main steps:\n",
        "1. Data loading and cleaning\n",
        "2. Feature extraction and transformation\n",
        "3. Model training with multiple regression algorithms\n",
        "4. Performance evaluation and visualization\n",
        "5. Feature importance analysis\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "caazVPKAnu5k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
        "from sklearn.linear_model import ElasticNet, HuberRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Function to extract baseline patient features\n",
        "def extract_baseline_features(df):\n",
        "    \"\"\"Extract baseline features from patient data\"\"\"\n",
        "    # Group by patient to get unique patient records\n",
        "    patients_df = df.groupby('PatientNum').agg({\n",
        "        'PatientAgeAtAdmission': 'first',\n",
        "        'TotalHospitalDays': 'first'\n",
        "    }).reset_index()\n",
        "\n",
        "    # Extract BMI and Weight as baseline features (using the latest value)\n",
        "    bmi_data = df[df['Parameter_Name'] == 'BMI'].sort_values('HoursFromAdmission')\n",
        "    weight_data = df[df['Parameter_Name'] == 'משקל'].sort_values('HoursFromAdmission')\n",
        "\n",
        "    # Create DataFrames with just the latest BMI and weight values\n",
        "    latest_bmi = bmi_data.groupby('PatientNum').last()[['NumericResult']].rename(\n",
        "        columns={'NumericResult': 'BMI'})\n",
        "    latest_weight = weight_data.groupby('PatientNum').last()[['NumericResult']].rename(\n",
        "        columns={'NumericResult': 'Weight'})\n",
        "\n",
        "    # Merge baseline features\n",
        "    patients_df = patients_df.merge(latest_bmi, on='PatientNum', how='left')\n",
        "    patients_df = patients_df.merge(latest_weight, on='PatientNum', how='left')\n",
        "\n",
        "\n",
        "    return patients_df\n",
        "\n",
        "# Function to process diagnosis data\n",
        "def prepare_diagnosis_features(diagnoses_df):\n",
        "    \"\"\"Process ICD9/ICD10 diagnoses into features for the model\"\"\"\n",
        "\n",
        "\n",
        "    # Convert patient number to numeric\n",
        "    if not pd.api.types.is_numeric_dtype(diagnoses_df['PatientNum']):\n",
        "        diagnoses_df['PatientNum'] = pd.to_numeric(diagnoses_df['PatientNum'], errors='coerce')\n",
        "    diagnoses_df = diagnoses_df.dropna(subset=['PatientNum'])\n",
        "    diagnoses_df['PatientNum'] = diagnoses_df['PatientNum'].astype(int)\n",
        "\n",
        "    # Handle ICD9 codes\n",
        "    diagnoses_df['ICD9'] = diagnoses_df['ICD9'].astype(str).str.strip()\n",
        "    diagnoses_df = diagnoses_df[diagnoses_df['ICD9'].str.len() > 0]\n",
        "    diagnoses_df['ICD9_category'] = diagnoses_df['ICD9'].str.extract(r'([A-Z]?[0-9]{1,3})')[0]\n",
        "\n",
        "\n",
        "\n",
        "    # Convert to string to prevent issues\n",
        "    diagnoses_df['ICD9_category'] = diagnoses_df['ICD9_category'].fillna('').astype(str)\n",
        "\n",
        "    # Create unique patient list\n",
        "    patient_diagnoses = pd.DataFrame(diagnoses_df['PatientNum'].unique(), columns=['PatientNum'])\n",
        "\n",
        "    # Add total diagnosis count\n",
        "    diagnosis_counts = diagnoses_df.groupby('PatientNum').size().reset_index(name='diagnosis_count')\n",
        "    patient_diagnoses = patient_diagnoses.merge(diagnosis_counts, on='PatientNum', how='left')\n",
        "\n",
        "    # Define disease categories\n",
        "    disease_categories = {\n",
        "        'infectious': ['001', '002', '003', '004', '005', '006', '007', '008', '009', '01', '02', '03', '04', '05', '06', '07', '08', '09', 'A', 'B'],\n",
        "        'neoplasms': ['14', '15', '16', '17', '18', '19', '20', '21', '22', '23', 'C', 'D0', 'D1', 'D2', 'D3', 'D4'],\n",
        "        'endocrine': ['24', '25', '26', '27', 'E'],\n",
        "        'blood': ['28', '29', 'D5', 'D6', 'D7', 'D8'],\n",
        "        'mental': ['29', '30', '31', 'F'],\n",
        "        'nervous': ['32', '33', '34', '35', '36', '37', 'G'],\n",
        "        'circulatory': ['39', '40', '41', '42', '43', '44', '45', 'I'],\n",
        "        'respiratory': ['46', '47', '48', '49', '50', '51', 'J'],\n",
        "        'digestive': ['52', '53', '54', '55', '56', '57', 'K'],\n",
        "        'genitourinary': ['58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', 'N'],\n",
        "        'pregnancy': ['63', '64', '65', '66', '67', 'O'],\n",
        "        'skin': ['68', '69', '70', '71', 'L'],\n",
        "        'musculoskeletal': ['71', '72', '73', 'M'],\n",
        "        'congenital': ['74', '75', 'Q'],\n",
        "        'perinatal': ['76', '77', 'P'],\n",
        "        'symptoms': ['78', '79', 'R'],\n",
        "        'injury': ['80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', 'S', 'T'],\n",
        "        'external_causes': ['E', 'V', 'W', 'X', 'Y'],\n",
        "        'factors': ['Z']\n",
        "    }\n",
        "\n",
        "    # Create mapping from ICD code to category\n",
        "    icd_to_category = {}\n",
        "    for category, codes in disease_categories.items():\n",
        "        for code in codes:\n",
        "            icd_to_category[code] = category\n",
        "\n",
        "    # Map each diagnosis to appropriate category\n",
        "    def get_prefix(icd_code):\n",
        "        if not icd_code or pd.isna(icd_code) or icd_code == '':\n",
        "            return ''\n",
        "        icd_code = str(icd_code).strip()\n",
        "        if len(icd_code) == 0:\n",
        "            return ''\n",
        "        if icd_code[0].isalpha():\n",
        "            return icd_code[0]  # First letter for ICD10 codes\n",
        "        else:\n",
        "            # Return first digit for ICD9 codes\n",
        "            return icd_code[:1]\n",
        "\n",
        "    # Apply safer function\n",
        "    diagnoses_df['prefix'] = diagnoses_df['ICD9_category'].apply(get_prefix)\n",
        "\n",
        "    # Map prefix to category\n",
        "    diagnoses_df['disease_category'] = diagnoses_df['prefix'].map(icd_to_category)\n",
        "    diagnoses_df['disease_category'] = diagnoses_df['disease_category'].fillna('other')\n",
        "\n",
        "\n",
        "    # Create flags for each disease category\n",
        "    for category in list(set(disease_categories.keys())) + ['other']:\n",
        "        category_counts = diagnoses_df[diagnoses_df['disease_category'] == category].groupby('PatientNum').size().reset_index(name=f'has_{category}')\n",
        "        patient_diagnoses = patient_diagnoses.merge(category_counts, on='PatientNum', how='left')\n",
        "        patient_diagnoses[f'has_{category}'] = patient_diagnoses[f'has_{category}'].fillna(0)\n",
        "\n",
        "        # Convert to binary flag\n",
        "        patient_diagnoses[f'has_{category}'] = (patient_diagnoses[f'has_{category}'] > 0).astype(int)\n",
        "\n",
        "    # Identify common diagnosis codes and add flags\n",
        "    valid_codes = diagnoses_df['ICD9_category'].dropna()\n",
        "    if len(valid_codes) > 0:\n",
        "        top_codes = valid_codes.value_counts().head(20).index\n",
        "\n",
        "        for code in top_codes:\n",
        "            if not pd.isna(code) and str(code).strip() != '':\n",
        "                code_counts = diagnoses_df[diagnoses_df['ICD9_category'] == code].groupby('PatientNum').size().reset_index(name=f'has_icd_{code}')\n",
        "                patient_diagnoses = patient_diagnoses.merge(code_counts, on='PatientNum', how='left')\n",
        "                patient_diagnoses[f'has_icd_{code}'] = patient_diagnoses[f'has_icd_{code}'].fillna(0)\n",
        "\n",
        "                # Convert to binary flag\n",
        "                patient_diagnoses[f'has_icd_{code}'] = (patient_diagnoses[f'has_icd_{code}'] > 0).astype(int)\n",
        "\n",
        "\n",
        "    return patient_diagnoses\n",
        "\n",
        "# Function to extract both counts and statistical summaries of vital sign measurements\n",
        "def extract_parameter_statistics(df):\n",
        "    \"\"\"Extract both counts and statistical summaries of vital sign measurements\"\"\"\n",
        "    parameters = ['דופק', 'לחץ סיסטולי', 'לחץ דיאסטולי', 'חום',\n",
        "                  'סטורציה', 'מספר נשימות', 'כאב', 'סוכר בדם']\n",
        "\n",
        "    patient_ids = df['PatientNum'].unique()\n",
        "    parameter_features = pd.DataFrame({'PatientNum': patient_ids})\n",
        "\n",
        "    for param in parameters:\n",
        "        param_data = df[df['Parameter_Name'] == param]\n",
        "\n",
        "        # Extract counts (monitoring frequency)\n",
        "        counts = param_data.groupby('PatientNum').size().reset_index(name=f'{param}_count')\n",
        "        parameter_features = parameter_features.merge(counts, on='PatientNum', how='left')\n",
        "        parameter_features[f'{param}_count'] = parameter_features[f'{param}_count'].fillna(0)\n",
        "\n",
        "        # For each patient, calculate statistics if they have measurements\n",
        "        stats_df = pd.DataFrame(columns=['PatientNum',\n",
        "                                         f'{param}_mean', f'{param}_median', f'{param}_std',\n",
        "                                         f'{param}_min', f'{param}_max', f'{param}_range', f'{param}_trend'])\n",
        "\n",
        "        for patient_id in patient_ids:\n",
        "            patient_param_data = param_data[param_data['PatientNum'] == patient_id]\n",
        "\n",
        "            if not patient_param_data.empty:\n",
        "                values = patient_param_data['NumericResult'].values\n",
        "\n",
        "                # Create a row with statistics\n",
        "                stats_row = {\n",
        "                    'PatientNum': patient_id,\n",
        "                    f'{param}_mean': np.mean(values),\n",
        "                    f'{param}_median': np.median(values),\n",
        "                    f'{param}_std': np.std(values) if len(values) > 1 else 0,\n",
        "                    f'{param}_min': np.min(values),\n",
        "                    f'{param}_max': np.max(values),\n",
        "                    f'{param}_range': np.max(values) - np.min(values),\n",
        "                    f'{param}_trend': values[-1] - values[0] if len(values) > 1 else 0\n",
        "                }\n",
        "\n",
        "                stats_df = pd.concat([stats_df, pd.DataFrame([stats_row])], ignore_index=True)\n",
        "\n",
        "        # Merge statistics with the main features dataframe\n",
        "        if not stats_df.empty:\n",
        "            parameter_features = parameter_features.merge(stats_df, on='PatientNum', how='left')\n",
        "\n",
        "            # Fill missing values with zeros for patients without measurements\n",
        "            for col in [f'{param}_mean', f'{param}_median', f'{param}_std',\n",
        "                        f'{param}_min', f'{param}_max', f'{param}_range', f'{param}_trend']:\n",
        "                parameter_features[col] = parameter_features[col].fillna(0)\n",
        "\n",
        "\n",
        "\n",
        "    return parameter_features\n",
        "\n",
        "# Function for hospitalization days prediction with baseline and statistical features\n",
        "def predict_hospitalization_days(df, diagnoses_df=None):\n",
        "    \"\"\"Predict hospitalization days using baseline features and vital sign statistics\"\"\"\n",
        "    # Extract baseline features\n",
        "    patients_df = extract_baseline_features(df)\n",
        "\n",
        "    # Extract parameter statistical features (includes counts and statistical summaries)\n",
        "    parameter_stats = extract_parameter_statistics(df)\n",
        "\n",
        "    # Merge baseline features with parameter statistics\n",
        "    X_df = patients_df.merge(parameter_stats, on='PatientNum', how='left')\n",
        "\n",
        "    # Prepare diagnosis features if available\n",
        "    if diagnoses_df is not None:\n",
        "        diagnosis_features_df = prepare_diagnosis_features(diagnoses_df)\n",
        "\n",
        "        # Merge diagnosis features\n",
        "        X_df = X_df.merge(diagnosis_features_df, on='PatientNum', how='left')\n",
        "\n",
        "        # Fill missing values\n",
        "        X_df = X_df.fillna(0)\n",
        "\n",
        "\n",
        "    # Separate features and target\n",
        "    y = X_df['TotalHospitalDays'].values\n",
        "    patient_ids = X_df['PatientNum'].values\n",
        "    X = X_df.drop(['PatientNum', 'TotalHospitalDays'], axis=1)\n",
        "\n",
        "    # Store feature names for later\n",
        "    feature_names = X.columns.tolist()\n",
        "\n",
        "    # Convert to numpy array\n",
        "    X = X.values\n",
        "\n",
        "    # Apply Winsorization - cap extreme values\n",
        "    upper_limit = 365  # Cap at 365 days (1 year)\n",
        "    y_capped = np.minimum(y, upper_limit)\n",
        "    capped_count = np.sum(y > upper_limit)\n",
        "\n",
        "    # Fill missing values and scale features\n",
        "    imputer = StandardScaler()\n",
        "    X_imputed = np.nan_to_num(X, nan=0)\n",
        "    X_scaled = imputer.fit_transform(X_imputed)\n",
        "\n",
        "\n",
        "    # Split data into training and testing sets\n",
        "    X_train, X_test, y_train_capped, y_test_original, train_ids, test_ids = train_test_split(\n",
        "        X_scaled, y_capped, patient_ids, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    # Also keep the original uncapped values for test set to evaluate true error\n",
        "    y_test = y_test_original.copy()\n",
        "\n",
        "\n",
        "\n",
        "    # Define multiple models to compare\n",
        "    models = {\n",
        "        'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42),\n",
        "        'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, random_state=42),\n",
        "        'AdaBoost': AdaBoostRegressor(n_estimators=100, random_state=42),\n",
        "        'Elastic Net': ElasticNet(random_state=42, alpha=0.1, l1_ratio=0.5),\n",
        "        'Huber Regressor': HuberRegressor(epsilon=1.35),\n",
        "        'SVR': SVR(kernel='rbf', C=10.0, gamma='auto')\n",
        "    }\n",
        "\n",
        "    # Train all models\n",
        "    trained_models = {}\n",
        "    model_performances = {}\n",
        "    predictions = {}\n",
        "\n",
        "    for name, model in models.items():\n",
        "        model.fit(X_train, y_train_capped)\n",
        "        trained_models[name] = model\n",
        "\n",
        "        # Make predictions\n",
        "        y_pred = model.predict(X_test)\n",
        "        predictions[name] = y_pred\n",
        "\n",
        "        # Evaluate performance\n",
        "        mae = mean_absolute_error(y_test, y_pred)\n",
        "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "        r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "        model_performances[name] = {\n",
        "            'MAE': mae,\n",
        "            'RMSE': rmse,\n",
        "            'R²': r2\n",
        "        }\n",
        "\n",
        "        print(f\"{name} Performance:\")\n",
        "        print(f\"  Mean Absolute Error: {mae:.2f} days\")\n",
        "        print(f\"  Root Mean Squared Error: {rmse:.2f} days\")\n",
        "        print(f\"  R² Score: {r2:.2f}\")\n",
        "\n",
        "    # Find the best model based on MAE\n",
        "    best_model_name = min(model_performances, key=lambda k: model_performances[k]['MAE'])\n",
        "    best_model = trained_models[best_model_name]\n",
        "    best_predictions = predictions[best_model_name]\n",
        "\n",
        "    # Create a DataFrame with predictions from the best model\n",
        "    predictions_df = pd.DataFrame({\n",
        "        'PatientNum': test_ids,\n",
        "        'Actual_Days': y_test,\n",
        "        'Predicted_Days': best_predictions,\n",
        "        'Error': y_test - best_predictions,\n",
        "        'Abs_Error': abs(y_test - best_predictions)\n",
        "    })\n",
        "\n",
        "\n",
        "\n",
        "    # Compare models visually\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    model_names = list(models.keys())\n",
        "    metrics = ['MAE', 'RMSE']\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Feature importance for tree-based models\n",
        "    if hasattr(best_model, 'feature_importances_'):\n",
        "        # Ensure feature_names length matches features\n",
        "        if len(feature_names) > len(best_model.feature_importances_):\n",
        "            feature_names = feature_names[:len(best_model.feature_importances_)]\n",
        "        elif len(feature_names) < len(best_model.feature_importances_):\n",
        "            # Extend feature names if needed\n",
        "            feature_names.extend([f'Feature_{i}' for i in range(len(feature_names), len(best_model.feature_importances_))])\n",
        "\n",
        "        importance_df = pd.DataFrame({\n",
        "            'Feature': feature_names,\n",
        "            'Importance': best_model.feature_importances_\n",
        "        })\n",
        "        importance_df = importance_df.sort_values('Importance', ascending=False)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    return best_model, predictions_df, model_performances, feature_names\n",
        "\n",
        "# Function to load data from file\n",
        "def load_from_uploaded_file(file_path):\n",
        "    \"\"\"Load patient data from a CSV file with headers\"\"\"\n",
        "    try:\n",
        "        # Read the file with its headers\n",
        "        df = pd.read_csv(file_path)\n",
        "\n",
        "        # List of expected columns\n",
        "        expected_columns = ['PatientNum', 'PatientAgeAtAdmission', 'TotalHospitalDays',\n",
        "                           'Execution_Date', 'HoursFromAdmission', 'Parameter_Name',\n",
        "                           'ResultValue', 'NumericResult', 'ReadingSequence']\n",
        "\n",
        "        # Check if all required columns are present\n",
        "        missing_columns = [col for col in expected_columns if col not in df.columns]\n",
        "\n",
        "        if missing_columns:\n",
        "            print(f\"Warning: Missing expected columns: {missing_columns}\")\n",
        "            print(f\"Available columns: {df.columns.tolist()}\")\n",
        "\n",
        "        # Convert numeric columns\n",
        "        numeric_columns = ['PatientNum', 'PatientAgeAtAdmission', 'TotalHospitalDays',\n",
        "                          'HoursFromAdmission', 'NumericResult']\n",
        "\n",
        "        for col in numeric_columns:\n",
        "            if col in df.columns:\n",
        "                df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "\n",
        "\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading data: {e}\")\n",
        "        # Last attempt - try to read a few lines as plain text\n",
        "        try:\n",
        "            with open(file_path, 'r', encoding='utf-8') as f:\n",
        "                for i in range(5):\n",
        "                    print(f.readline().strip())\n",
        "        except:\n",
        "            pass\n",
        "        return None\n",
        "\n",
        "# Main execution function\n",
        "def main(vital_signs_file='over_20_records.csv', diagnoses_file='patients_diagnoses.csv'):\n",
        "    \"\"\"Main function to load data and run the prediction model\"\"\"\n",
        "    # Load the vital signs data\n",
        "    try:\n",
        "        df = load_from_uploaded_file(vital_signs_file)\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading vital signs data: {e}\")\n",
        "        return None, None, None, None\n",
        "\n",
        "    # Load diagnoses data if file provided\n",
        "    diagnoses_df = None\n",
        "    if diagnoses_file:\n",
        "        try:\n",
        "            diagnoses_df = pd.read_csv(diagnoses_file)\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading diagnoses data: {e}\")\n",
        "            print(\"Continuing without diagnoses data.\")\n",
        "\n",
        "    if df is not None:\n",
        "        # Run the prediction model with baseline and statistical features\n",
        "        best_model, predictions_df, model_performances, feature_names = predict_hospitalization_days(df, diagnoses_df)\n",
        "\n",
        "\n",
        "        return best_model, predictions_df, model_performances, feature_names\n",
        "    else:\n",
        "        print(\"Failed to load data. Please check the file format.\")\n",
        "        return None, None, None, None\n",
        "\n",
        "# Run the model\n",
        "if __name__ == \"__main__\":\n",
        "    # Run the model with vital signs and diagnoses data\n",
        "    best_model, predictions_df, model_performances, feature_names = main(\"over_20_records.csv\", \"patients_diagnoses.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        },
        "id": "emUHqvc2mYPo",
        "outputId": "4555c025-9760-4e93-eefc-cdf1a7fb9d9e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Performance:\n",
            "  Mean Absolute Error: 21.61 days\n",
            "  Root Mean Squared Error: 36.71 days\n",
            "  R² Score: 0.46\n",
            "Gradient Boosting Performance:\n",
            "  Mean Absolute Error: 21.65 days\n",
            "  Root Mean Squared Error: 37.21 days\n",
            "  R² Score: 0.44\n",
            "AdaBoost Performance:\n",
            "  Mean Absolute Error: 34.52 days\n",
            "  Root Mean Squared Error: 44.83 days\n",
            "  R² Score: 0.19\n",
            "Elastic Net Performance:\n",
            "  Mean Absolute Error: 23.12 days\n",
            "  Root Mean Squared Error: 39.11 days\n",
            "  R² Score: 0.39\n",
            "Huber Regressor Performance:\n",
            "  Mean Absolute Error: 22.51 days\n",
            "  Root Mean Squared Error: 42.21 days\n",
            "  R² Score: 0.28\n",
            "SVR Performance:\n",
            "  Mean Absolute Error: 23.51 days\n",
            "  Root Mean Squared Error: 49.25 days\n",
            "  R² Score: 0.03\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare Diagnosis"
      ],
      "metadata": {
        "id": "czY8J5r91q-e"
      }
    }
  ]
}